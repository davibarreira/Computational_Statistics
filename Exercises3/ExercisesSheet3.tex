\documentclass[12pt,letterpaper]{article}
\usepackage{./preamble}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Edit These for yourself
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand\course{Computational Statistics}
\newcommand\hwnumber{2}
\newcommand\userID{Davi Sales Barreira}
\DeclareRobustCommand{\rchi}{{\mathpalette\irchi\relax}}
\newcommand{\irchi}[2]{\raisebox{\depth}{$#1\chi$}}
\newcommand*{\QEDA}{\hfill\ensuremath{\blacksquare}}%

\begin{document}
% \textbf{\Large Worksheet completed with Octave.}

\section*{Exercise 1 (Gibbs Sampler)}
\begin{enumerate}[leftmargin=!,labelindent=5pt]
\item First, let $X' = X^{(t)}$, $X = X^{(t-1)}$, $Y' = Y^{(t)}$ and
$Y = Y^{(t-1)}$
. Then:
$$
K^S((x,y),(x',y')) = \pi_{Y\mid X}(y' \mid x) \pi_{X \mid Y}(x' \mid y')
$$

Then, to show that it is not reversible:
$$
\pi(x,y)K((x,y),(x',y')) = \pi(x,y) \pi(y' \mid x) \pi(x' \mid y')
$$
$$ 
\pi(x',y')K((x',y'),(x,y)) = \pi(x',y') \pi(y \mid x') \pi(x \mid y)
$$
$$
\therefore
$$
$$
\frac{\pi(x,y)K((x,y),(x',y'))}
{\pi(x',y')K((x',y'),(x,y))} =
\frac{\pi(x,y) \pi(y' \mid x) \pi(x' \mid y')}
{\pi(x',y') \pi(y \mid x') \pi(x \mid y)} = 
\frac{\pi(y)\pi(y' \mid x)}
{\pi(y')\pi(y \mid x')} \neq 1
$$
Therefore, it is not reversible.
\qed

\item First, the kernel expression:
$$
K(x, x') = \int \pi(y' \mid x) \pi(x' \mid y') dy'
$$

Now, let's show that it is $\pi_X$-reversible.
$$
\pi(x')K(x', x) = \pi(x') \int \pi(y \mid x') \pi(x \mid y) dy
=
\int \pi(x') \frac{\pi(y,x')}{\pi(x')}\pi(x\mid y) dy =
$$
$$
=
\int \pi(y,x') \pi(x \mid y) dy = 
\int \pi(y,x') \frac{\pi(x,y)}{\pi(y)}dy =
\int \pi(x,y) \frac{\pi(x',y)}{\pi(y)}dy =
$$
$$
= \pi(x)\int \pi(y \mid x) \pi(x' \mid y)  dy = \pi(x)K(x,x')
$$
\qed

\item First, the kernel expression is:
$$
K^R((x,y),(x',y')) = 
\pi(y' \mid x)\pi(x' \mid y')0.5 + \pi(x' \mid y)\pi(y' \mid x')0.5
$$
Note that it is half the density of sampling first from $y$ plus 
half the density of sampling first from $x$.

Now, let's show that it is reversible:
$$
\frac{\pi(x,y)[\pi(y' \mid x)\pi(x' \mid y')0.5 +
\pi(x' \mid y)\pi(y' \mid x')0.5]}
{
\pi(x',y')[\pi(y \mid x')\pi(x \mid y')0.5 +
\pi(x \mid y')\pi(y \mid x)0.5 ]
} = 
$$
$$ =
\frac{
	\frac{\pi(y' \mid x)}
	{\pi(y')}
	+
	\frac{\pi(x' \mid y)}
	{\pi(x')}
}
{
	\frac{\pi(y \mid x')}
	{\pi(y)}
	+
	\frac{\pi(x \mid y')}
	{\pi(x)}
} = 
1
$$
\qed
\end{enumerate}

\newpage
\section*{Exercise 2 (Metropolis-within-Gibbs)}
\begin{enumerate}[leftmargin=!,labelindent=5pt]
\item Note that:
$$
\alpha(X_1 \mid X_1^{(t-1)}, X_2^{(t-2)}) =
min \left\{
1,
\frac{\pi(X_1' , X_2^{(t-1)})\pi(X_1^{(t-1)}\mid X_2^{(t-1)})}
{\pi(X_1^{(t-1)} , X_2^{(t-1)})\pi(X_1'\mid X_2^{(t-1)})}
\right\} = min \{1, 1\}
$$
Therefore, we get a systematic scan Gibbs sampler, where one
samples $X^t_1 \sim \pi(\cdot \mid X_2^{(t-1)})$, then we accept,
since $\alpha=1$, and finally sample $X_2^t \sim
\pi(\cdot \mid X_1^{(t)})$.
\qed

\item First, let's write the kernel. Since we only accept or reject
the variabel $X_1$, the kernel is the M-H kernel multiplied by the
probability density function of $\pi_{X_2\mid X_1}(X_2\mid X_1)$. Let
$X_1^t, X_2^t = Y_1, Y_2$:
$$
K((x_1,x_2),(y_1, y_2)) =
(q(y_1 \mid x_1, x_2)\alpha(y_1 \mid x_1,x_2)) +
(1 - a(y_1 \mid x_1, x_2))\delta_{y_1}(x_1)\pi_{(Y_2\mid Y_1}(y_2 \mid y_1)
$$
Note that $\alpha = 1$. With that, we show that the kernel is invarant:

$$
\int \int
K((x_1,x_2),(y_1, y_2))\pi(x_1,x_2) dx_1 dx_2 =
\int \int \pi(y_1 \mid x_2)\pi(y_2 \mid y_1) \pi(x_1, x_2)dx_1 dx_2 =
$$
$$=
\int \pi(y_1 \mid x_2) \pi(y_2 \mid y_1) \pi(x_2) dx_2 =
\int \pi(y_1, x_2)\pi(y_2 \mid y_1) dx_2 = \pi(y_1, y_2)
$$
\qed

\end{enumerate}

\newpage
\section*{Exercise 3 (Metropolis-Hastings and Gibbs Sampler)}
\begin{enumerate}[leftmargin=!,labelindent=5pt]
\item  Let's show that the chain is reversible. If $x=y$, it is trivially
reversible. If $x \neq y$, then:
$$
T(x,y) \pi(x) = \alpha(x,y)q(x,y)\pi(x) =
\frac{\gamma(x,y)}{\pi(x)q(x,y)}q(x,y)\pi(x) = \gamma(y,x) =
$$
$$
= \alpha(y,x) q(y,x) \pi(y) = T(y,x) \pi(y)
$$
\qed

\item First, let's verify that it is the M-H algorithm:
$$
\alpha = \frac{\gamma(x,y)}{\pi(x)q(x,y)} = 
\frac{min \{  \pi(x) q(x,y), \pi(y) q(y,x) \}}
{\pi(x) q(x,y)} =
min \left \{
	1, \frac{\pi(y)q(y,x)}
	{\pi(x)q(x,y)}
\right\}
$$

Now, let's give the Barker acceptance ratio:
$$
\alpha(x,y) = \frac{\pi(x)q(x,y)\pi(y)q(y,x)}
{\pi(x)q(x,y)+\pi(y)q(y,x)} =
\frac{\pi(y)q(y,x)}{\pi(x)q(x,y) + \pi(y)q(y,x)}
$$
\qed

\item Let's consider $x \neq y$. Note that:
$$
\frac{1}{\pi(x)q(x,y)}
\geq
\frac{1}{\pi(x)q(x,y) + \pi(y)q(y,x)}
$$
$$
\therefore
$$
$$
\frac{\pi(y)q(y,x)q(x,y)}{\pi(x)q(x,y)}
\geq
\frac{q(x,y)\pi(y)q(y,x)}{\pi(x)q(x,y) + \pi(y)q(y,x)}
$$

Finally, if $\frac{\pi(y)q(y,x)q(x,y)}{\pi(x)q(x,y)} \leq 1$, then:

$$
min\left \{
1,
\frac{\pi(y)q(y,x)q(x,y)}{\pi(x)q(x,y)}
\right\}
\geq
\frac{q(x,y)\pi(y)q(y,x)}{\pi(x)q(x,y) + \pi(y)q(y,x)}
$$

We conclude that the M-H algorithm provides estimators with
lower asymptotic variance than Barker's algorithm.

\item First, since the probability of chosing and index is the same
for both algorithms, it is not important when showing which
kernel is bigger of equal than the other. Now, consider $x \neq y$.

Modified: $T(x_k^{(t-1)}, x_k^*) =
min\left\{
1, \frac{1- \pi(x_k^{(t-1)} \mid x_{-k})}{1 -  \pi(x_k^* \mid x_{-k})}
\right\}
\frac{\pi(x_k^* \mid x_{-k})}{1- \pi(x_k^{(t-1)} \mid x_{-k})}$

Standard: $T(x_k^{(t-1)}, x_k^*) = \pi(x_k^* \mid x_{-k})$

Let's consider both cases for the Modified kernel, hence, when
$\alpha = 1$ and
$\alpha =
\frac{1- \pi(x_k^{(t-1)} \mid x_{-k})}{1 -  \pi(x_k^* \mid x_{-k})} $
First, since $1- \pi(x_k^{(t-1)} \mid x_{-k})\leq 1$, we have:
$$
1 \cdot\frac{\pi(x_k^* \mid x_{-k})}{1- \pi(x_k^{(t-1)} \mid x_{-k})}
\geq
\pi(x_k^* \mid x_{-k})
$$

Also:
$$
\frac{1- \pi(x_k^{(t-1)} \mid x_{-k})}{1 -  \pi(x_k^* \mid x_{-k})}
\cdot\frac{\pi(x_k^* \mid x_{-k})}{1- \pi(x_k^{(t-1)} \mid x_{-k})}
\geq
\pi(x_k^* \mid x_{-k})
$$
Therefore, the modified kernel provides estimators
with lower assymptotic variance.
\qed
\end{enumerate}

\newpage
\section*{Exercise 4 (Metropolis-Hastings)}
\begin{enumerate}[leftmargin=!,labelindent=5pt]
\item Let $Y = X'$, $\theta = v'$:
$$q(y \mid x) = \int f(v \mid x) g(y \mid v) dv$$
$$
\alpha_{MH} = min \left \{ 1,
\frac{\pi(y)\int f(v \mid y) g(x \mid v) dv}
{\pi(x)\int f(v \mid x) g(y \mid v) dv}
\right \}
$$
Since we the density function $f(v \mid x)$ is unknown, then we cannot 
evaluate this $\alpha_{MH}$.

\item Let's show that the chain is invariant:
$$
\int \int \pi(x,v) g(y \mid v) f(\theta \mid y)
\cdot min \left \{
1, \frac{\pi(y)g(x \mid \theta)}{\pi(x)g(y\mid v)}
\right\} dv dx = 
$$
If $\alpha =1 $, then

$$
\int \pi(v) g(y \mid v) f(\theta \mid y)
\cdot 1
dv = f(\theta \mid y) \pi(y) = \bar\pi(y, \theta)
$$

Else:
$$
\int \int \pi(x,v) g(y \mid v) f(\theta \mid y)
\cdot 
\frac{\pi(y)g(x \mid \theta)}{\pi(x)g(y\mid v)}
dv dx = 
\int \pi(y) f(\theta \mid y) g(x \mid \theta) dx =
$$
$$
= \pi(y) f(\theta \mid y) = \bar\pi(y, \theta)
$$

Finally, $\bar\pi(y) = \int \bar\pi(y,\theta) d\theta = 
\int \pi(y) f(\theta \mid y) d\theta = \pi(y)$.

\qed



\end{enumerate}

\end{document}
